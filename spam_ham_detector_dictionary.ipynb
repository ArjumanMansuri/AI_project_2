{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "import matplotlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamDictionary = {}\n",
    "spamDictionary = {}\n",
    "vocabulary = set()\n",
    "\n",
    "def word_count_directory(directory):\n",
    "    filelist=[os.path.join(directory,f) for f in os.listdir(directory)]\n",
    "    noOfSpamFiles = 0\n",
    "    noOfHamFiles = 0\n",
    "    for file_path in filelist:\n",
    "        with open(file_path,encoding='latin-1') as infile:\n",
    "            # to store type of file 'spam' or 'ham'\n",
    "            file_type = ''\n",
    "            if 'spam' in file_path:\n",
    "                file_type = 'spam'\n",
    "                noOfSpamFiles += 1\n",
    "            elif 'ham' in file_path:\n",
    "                file_type = 'ham'\n",
    "                noOfHamFiles += 1\n",
    "            # Loop through each line of the file \n",
    "            for line in infile:\n",
    "                # Remove the leading spaces and newline character \n",
    "                line = line.strip()\n",
    "                # Convert the characters in line to lowercase to avoid case mismatch \n",
    "                lowerLine = str.lower(line)\n",
    "                validWords = re.split('[^a-zA-Z]',lowerLine)\n",
    "                # Iterate over each word in line \n",
    "                for word in validWords:\n",
    "                    # if the word is not an empty space\n",
    "                    if len(word) > 0:\n",
    "                        \n",
    "                        if file_type=='ham':\n",
    "                            # Check if the word is already in dictionary\n",
    "                            if word in hamDictionary:\n",
    "                                hamDictionary[word] += 1\n",
    "                            else:\n",
    "                                # add word to dictionary with count 1\n",
    "                                hamDictionary[word] = 1\n",
    "                                # add word to vocabulary set\n",
    "                                vocabulary.add(word)\n",
    "                                # if this word is not present in spamDictionary, add it with count 0\n",
    "                                if word not in spamDictionary:\n",
    "                                    spamDictionary[word] = 0\n",
    "                                \n",
    "                        elif file_type=='spam':\n",
    "                            # Check if the word is already in dictionary\n",
    "                            if word in spamDictionary:\n",
    "                                spamDictionary[word] += 1\n",
    "                            else:\n",
    "                                # add word to dictionary with count 1\n",
    "                                spamDictionary[word] = 1\n",
    "                                # add word to vocabulary set\n",
    "                                vocabulary.add(word)\n",
    "                                # if this word is not present in hamDictionary, add it with count 0\n",
    "                                if word not in hamDictionary:\n",
    "                                    hamDictionary[word] = 0\n",
    "    return noOfSpamFiles,noOfHamFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_total, ham_total = word_count_directory(directory)\n",
    "total = spam_total + ham_total\n",
    "priorProbOfSpam = spam_total / total\n",
    "priorProbOfHam = ham_total / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary,hamDictionary,spamDictionary):\n",
    "    # sorting the vocabulary to maintain order in model.txt\n",
    "    vocabulary = sorted(vocabulary)\n",
    "    # creating file that would store the model\n",
    "    f= open(\"model.txt\",\"w+\")\n",
    "    # getting size of vocabulary\n",
    "    N = len(vocabulary)\n",
    "    # smoothing value\n",
    "    delta = 0.5\n",
    "    smoothed_N = (delta * N)\n",
    "    # calculating smoothed denominator while calculating condinational probability of ham words\n",
    "    ham_denominator = sum(hamDictionary.values()) + smoothed_N\n",
    "    \n",
    "    # calculating smoothed denominator while calculating condinational probability of spam words\n",
    "    spam_denominator = sum(spamDictionary.values()) + smoothed_N\n",
    "    \n",
    "    for i,word in enumerate(vocabulary):\n",
    "        \n",
    "        # frequency of word in ham dictionary\n",
    "        freq_in_ham = hamDictionary[word]\n",
    "        # conditional probabiltiy of word in ham\n",
    "        c_p_in_ham = (freq_in_ham + delta) / ham_denominator\n",
    "        # frequency of word in spam dictionary\n",
    "        freq_in_spam = spamDictionary[word]\n",
    "        # conditional probabiltiy of word in spam\n",
    "        c_p_in_spam = (freq_in_spam + delta) / spam_denominator\n",
    "        hamDictionary[word]=c_p_in_ham\n",
    "        spamDictionary[word]=c_p_in_spam\n",
    "        \n",
    "        # writing all the data to model.txt\n",
    "        f.write(str(i+1)+'  '+word+'  '+str(freq_in_ham)+'  '+str( \"{:.8f}\".format(float( c_p_in_ham )) )+'  '+str(freq_in_spam)+'  '+str( \"{:.8f}\".format(float( c_p_in_spam )) )+'\\n')\n",
    "    # closing the file\n",
    "    f.close()\n",
    "    \n",
    "create_model(vocabulary,hamDictionary,spamDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_test=[]\n",
    "logOfHam = math.log10(priorProbOfHam)\n",
    "logOfSpam = math.log10(priorProbOfSpam)\n",
    "\n",
    "truePositive = 0   # correct Ham -> result Ham\n",
    "trueNegative = 0    # correct Spam -> result Spam\n",
    "falsePositive = 0    # correct Spam -> result Ham\n",
    "falseNegative = 0    # correct Ham -> result Spam\n",
    "\n",
    "filelist=[os.path.join(\"test/\",f) for f in os.listdir(\"test/\")]\n",
    "tempCounter=0\n",
    "\n",
    "f = open(\"result.txt\", \"w+\")   # 'w+' for reading and writing\n",
    "f.truncate(0)\n",
    "\n",
    "for file_path in filelist:\n",
    "    \n",
    "    with open(file_path,encoding='latin-1') as infile:\n",
    "\n",
    "        fileName =file_path.rsplit('/',1)[1]\n",
    "        tempCounter=tempCounter+1;\n",
    "        scoreLogHam=logOfHam     # score for ham\n",
    "        scoreLogSpam=logOfSpam    # score for spam\n",
    "\n",
    "        if(\"test-ham\" in file_path):\n",
    "            correctClassification=\"ham\"\n",
    "        else:\n",
    "            correctClassification=\"spam\"\n",
    "\n",
    "        vocab_test=[]\n",
    "        for line in infile:\n",
    "\n",
    "            line = line.strip() \n",
    "            line = line.lower()\n",
    "            words=re.split('[^a-zA-Z]',line)\n",
    "            words=list(filter(None, words))\n",
    "            vocab_test=vocab_test+words\n",
    "\n",
    "\n",
    "        for word in vocab_test:\n",
    "            if word in vocabulary:\n",
    "                scoreLogHam=scoreLogHam+math.log10(hamDictionary[word])     \n",
    "                scoreLogSpam=scoreLogSpam+ math.log10(spamDictionary[word])\n",
    "        \n",
    "\n",
    "        if(scoreLogHam>scoreLogSpam):\n",
    "            predictedClassification=\"ham\"\n",
    "        else:\n",
    "            predictedClassification=\"spam\"\n",
    "\n",
    "        if(correctClassification == predictedClassification):\n",
    "            lable=\"right\"\n",
    "        else:\n",
    "            lable=\"wrong\"\n",
    "\n",
    "        if(correctClassification==\"ham\" and predictedClassification==\"ham\"):\n",
    "            truePositive=truePositive+1\n",
    "        elif(correctClassification==\"spam\" and predictedClassification==\"spam\"):\n",
    "            trueNegative=trueNegative+1\n",
    "        elif(correctClassification==\"spam\" and predictedClassification==\"ham\"):\n",
    "            falsePositive=falsePositive+1\n",
    "        elif(correctClassification==\"ham\" and predictedClassification==\"spam\"):\n",
    "            falseNegative=falseNegative+1\n",
    "\n",
    "        scoreLogHam= str( \"{:.8f}\".format(float( scoreLogHam )) )\n",
    "        scoreLogSpam=str( \"{:.8f}\".format(float( scoreLogSpam )))\n",
    "        f.write(str(str(tempCounter)+\" \"+str(fileName)+\" \"+str(predictedClassification)+\" \"+str(scoreLogHam)+\" \"+str(scoreLogSpam)+\" \"+str(correctClassification)+\" \"+str(lable)+\"\\n\"))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "336\n",
      "64\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(truePositive)\n",
    "print(trueNegative)\n",
    "print(falsePositive)\n",
    "print(falseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
