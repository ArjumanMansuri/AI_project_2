{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import matplotlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:/Users/emnsrjm/Desktop/Courses/AI/Project/Assignment_2/sample_data\"\n",
    "vocabulary = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamDictionary = {}\n",
    "spamDictionary = {}\n",
    "vocabulary = set()\n",
    "def word_count_directory(directory):\n",
    "    filelist=[os.path.join(directory,f) for f in os.listdir(directory)]\n",
    "    \n",
    "    for file_path in filelist:\n",
    "        with open(file_path) as infile:\n",
    "            # to store type of file 'spam' or 'ham'\n",
    "            file_type = ''\n",
    "            if 'spam' in file_path:\n",
    "                file_type = 'spam'\n",
    "            elif 'ham' in file_path:\n",
    "                file_type = 'ham'\n",
    "            # Loop through each line of the file \n",
    "            for line in infile:\n",
    "                # Remove the leading spaces and newline character \n",
    "                line = line.strip()\n",
    "                # Convert the characters in line to lowercase to avoid case mismatch \n",
    "                lowerLine = str.lower(line)\n",
    "                validWords = re.split('[^a-zA-Z]',lowerLine)\n",
    "                # Iterate over each word in line \n",
    "                for word in validWords:\n",
    "                    # if the word is not an empty space\n",
    "                    if len(word) > 0:\n",
    "                        \n",
    "                        if file_type=='ham':\n",
    "                            # Check if the word is already in dictionary\n",
    "                            if word in hamDictionary:\n",
    "                                hamDictionary[word] += 1\n",
    "                            else:\n",
    "                                # add word to dictionary with count 1\n",
    "                                hamDictionary[word] = 1\n",
    "                                # add word to vocabulary set\n",
    "                                vocabulary.add(word)\n",
    "                                # if this word is not present in spamDictionary, add it with count 0\n",
    "                                if word not in spamDictionary:\n",
    "                                    spamDictionary[word] = 0\n",
    "                                \n",
    "                        elif file_type=='spam':\n",
    "                            # Check if the word is already in dictionary\n",
    "                            if word in spamDictionary:\n",
    "                                spamDictionary[word] += 1\n",
    "                            else:\n",
    "                                # add word to dictionary with count 1\n",
    "                                spamDictionary[word] = 1\n",
    "                                # add word to vocabulary set\n",
    "                                vocabulary.add(word)\n",
    "                                # if this word is not present in hamDictionary, add it with count 0\n",
    "                                if word not in hamDictionary:\n",
    "                                    hamDictionary[word] = 0\n",
    "    \n",
    "word_count_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary,hamDictionary,spamDictionary):\n",
    "    # sorting the vocabulary to maintain order in model.txt\n",
    "    vocabulary = sorted(vocabulary)\n",
    "    # creating file that would store the model\n",
    "    f= open(\"model.txt\",\"w+\")\n",
    "    # getting size of vocabulary\n",
    "    N = len(vocabulary)\n",
    "    # smoothing value\n",
    "    delta = 0.5\n",
    "    smoothed_N = (delta * N)\n",
    "    # calculating smoothed denominator while calculating condinational probability of ham words\n",
    "    ham_denominator = sum(hamDictionary.values()) + smoothed_N\n",
    "    # calculating smoothed denominator while calculating condinational probability of spam words\n",
    "    spam_denominator = sum(spamDictionary.values()) + smoothed_N\n",
    "    \n",
    "    for i,word in enumerate(vocabulary):\n",
    "        \n",
    "        # frequency of word in ham dictionary\n",
    "        freq_in_ham = hamDictionary[word]\n",
    "        # conditional probabiltiy of word in ham\n",
    "        c_p_in_ham = (freq_in_ham + delta) / ham_denominator\n",
    "\n",
    "        # frequency of word in spam dictionary\n",
    "        freq_in_spam = spamDictionary[word]\n",
    "        # conditional probabiltiy of word in spam\n",
    "        c_p_in_spam = (freq_in_spam + delta) / spam_denominator\n",
    "        \n",
    "        # writing all the data to model.txt\n",
    "        f.write(str(i+1)+'  '+word+'  '+str(freq_in_ham)+'  '+str(c_p_in_ham)+'  '+str(freq_in_spam)+'  '+str(c_p_in_spam)+'\\n')\n",
    "        \n",
    "    # closing the file\n",
    "    f.close()\n",
    "create_model(vocabulary,hamDictionary,spamDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
